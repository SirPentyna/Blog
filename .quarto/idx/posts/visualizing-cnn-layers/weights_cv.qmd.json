{"title":"Visualizing CNNs","markdown":{"yaml":{"title":"Visualizing CNNs","author":"Aleksandra Muciek","date":"2023-03-27","categories":["ComputerVision","code"],"toc":true,"format":{"html":{"code-fold":true}}},"headingText":"Convolutional neural nets","containsRefs":false,"markdown":"\n\n\n\nEven though the concept of convolutional neural networks is not new to me, I noticed a gap in my understanding. I couldn't figure out how to approach visualization of convolutional neural network layers' weights. It alweays seemed odd to me when I looked at examples found online. \n\nHere I will try to explore the concept to teach myself this interesting thing.\n\n\nIn convolutional neural networks we operate on images. Each one is 2D grid of values representing every pixel. If the picture is in grayscale we only care for how dark or light each pixel is, so each image is represented as grid $n_{row} \\times n_{col}$ with values representing darkness of each pixel.\n\nIf we use color pictures, we divide it into $3$ channels - red, green, blue. For image with pixel size $n_{row} \\times n_{col}$ we use one grid for red coulour, second for green and third for blue. This means each picture is represented with 3 grids one on top of the other. Dimensionality of this thing is $(n_{row}, n_{col}, 3)$.\n\n![Layers of images. On the left grayscale image represented by only one matrix, on the right 3 channels of a colorful image.](imgaes_layers.png)\n\n### Filters\n\nFilters are introduced to smartly downscale an image while distilling the most important information convayed by the image. If we go back to grayscale setting, and assume we have $(n_{row}, n_{col}, 1)$ image, a single grid with pixel values, we introduce filter, for example $2 \\times 2$ matrix that will be put on top of the image, place by place where it fits. Then we will calculate elementwise product of each overlaping entries, sum the values and we will end up with a smaller image.\n\n![Example of grayscale image and $2\\times 2$ filter](grayscale_image_and_filter.png)\n\n\n![Applying $2 \\times 2$ filter to the example above.](applying_filters.png)\n\nWhile constructing a concloutional layer in the model, we specify the size of a filter ($2 \\times 2$, $3 \\times 3$ etc.) and we decide on the number of filters we want to apply. In the example above we used only one filter but we could repeat the above process with the second one with different values than $(1, 0),(2, 4)$. In the example above we got output  with dimensions $(3, 3, 1)$. If we chose to apply second filter we would get second result, so overal thing would have dimensions $(3, 3, 2)$. For specified number of filters $k$ we would get $(3, 3, k)$ dimensional tensor. \n\nValues of the filters are not specified by us before training - they are learned by the model. These are the things we may want ti visualize later to see how the model behaves.\n\n## Get convolutional model\n\nWe get a trained model from `keras` package called VGG16. Out of this model we will look for convolutional layers.\n\n```{python}\nimport numpy as np\n\n\nfrom keras.applications.vgg16 import VGG16\nmodel = VGG16()\n\n#model.summary()\n\nfor idx, layer in enumerate(model.layers):\n    if 'conv' in layer.name:\n        filters, biases = layer.get_weights()\n        print(f\"Index: {idx})\", layer.name, filters.shape)\n\n#weights from the second layer\n\nfilters, biases = model.layers[1].get_weights()\n\n#scaling\nf_min, f_max = filters.min(), filters.max()\nfilters = (filters - f_min) / (f_max - f_min)\n```\n\n## Plot some filters\n\nHere are presented some filters.\n\n```{python}\n#| label: fig-bnwfilters\n#| fig-cap: \"Every row is a visualized $3 \\times 3$ filter with every column being a channel of that filter. \"\nimport matplotlib.pyplot as plt\n\nnum_filters = 4\n\nfig, axs = plt.subplots(num_filters, filters.shape[2], sharey=True, figsize=(8, 12))\nfig.suptitle(\"Visualization of weights\")\nfor i in range(num_filters):\n    filter_0 = filters[:,:,:, i]\n    for j in range(filter_0.shape[2]):\n        axs[i,j].imshow(filter_0[:,:, j], cmap='gray')\n```\n\n\n\n```{python}\n\nfig, axs = plt.subplots(5, 5, sharey=True, figsize = (8,8))\nfig.suptitle(\"Filters with all 3 channels\")\nfor i in range(5):\n    for j in range(5):\n        axs[i, j].imshow(filters[:,:,:, i*5 + j])\n\n```\n\n## Additional section to play with widgets\n\n```{python}\n\n```\n\n## Useful links "},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"weights_cv.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","theme":"cosmo","title-block-banner":true,"title":"Visualizing CNNs","author":"Aleksandra Muciek","date":"2023-03-27","categories":["ComputerVision","code"]},"extensions":{"book":{"multiFile":true}}}}}