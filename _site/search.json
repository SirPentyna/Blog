[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Aleksandra Muciek",
    "section": "",
    "text": "Aleksandra is a Data Scientist at Predica, Software ONE company. She enjoys data and walks with her dog. In her free time she creates the finest art she can."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Up to Data",
    "section": "",
    "text": "Copula\n\n\n\n\n\n\n\nMath\n\n\ntheory\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2023\n\n\nAleksandra Muciek\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZbieżności rozkładów\n\n\n\n\n\n\n\nprobability\n\n\ntheory\n\n\npolish\n\n\nmathematics\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\nAleksandra Muciek\n\n\n\n\n\n\n  \n\n\n\n\nVisualizing CNNs\n\n\n\n\n\n\n\nComputerVision\n\n\ncode\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\nAleksandra Muciek\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMar 24, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/copula/index.html",
    "href": "posts/copula/index.html",
    "title": "Copula",
    "section": "",
    "text": "What are copulas? Why do we need them? How do we use them?"
  },
  {
    "objectID": "posts/copula/index.html#copulae---what-are-they",
    "href": "posts/copula/index.html#copulae---what-are-they",
    "title": "Copula",
    "section": "Copulae - what are they?",
    "text": "Copulae - what are they?\nCopulae came from the need of modeling relations between random variables.\nAssume we have random variables \\(X\\) and \\(Y\\) with distributions \\(F_X\\) and \\(F_Y\\). If they are independent, their joint distribution is given as \\(F_{X,Y}(x, y) = F_X(x)F_Y(y)\\). But what if they are not independent? There are numerous ways the variables could influence each other.\nHere comes Copula.\nEvery cumulative distribution function with uniform marginals on \\(U[0,1]\\) is called copula. Why is this is useful? Because we know that \\(F_X(X)\\) is uniformly distributed on \\([0,1]\\). With random variables \\(X\\), \\(Y\\) we can go to uniform random variables by \\(F_X(X)\\), \\(F_Y(Y)\\) and explore their dependance there, on \\([0, 1] \\times [0,1]\\)."
  },
  {
    "objectID": "posts/copula/index.html#existence",
    "href": "posts/copula/index.html#existence",
    "title": "Copula",
    "section": "Existence",
    "text": "Existence\nCan we do that trick for any pair of \\(X\\) and \\(Y\\)? It turns out that yes.\nSklar theorem\n\nTheorem 1 (Sklar) If \\(F_{(X,Y)}\\) is a cdf function of random variables \\((X, Y)\\) with continuous marginal cdfs \\(F_X\\) and \\(F_Y\\), there exists unique Copula such that\n\\[\nF_{(X, Y)}(x, y) = C_{(X,Y)}(F_X(x), F_Y(y))\n\\]\n\n\nProof. Take \\[\nC_(X, Y)(x, y) := P[F_X(X) \\leq x, F_Y(Y) \\leq y],\n\\] then \\[\nC_(X, Y)(x, y) = F_{(X,Y)} (F^{-1}_X(x), F^{-1}_Y(y)).\n\\]"
  },
  {
    "objectID": "posts/copula/index.html#examples",
    "href": "posts/copula/index.html#examples",
    "title": "Copula",
    "section": "Examples",
    "text": "Examples\nImportant examples:\n\nIndependent \\(X\\) and \\(Y\\) \\[\nC^{*} (x, y) = \\min (1, x) \\min (1, y) I_{(0, \\infty) \\times (0, \\infty)} (x, y)\n\\]\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_copula(copula_function, copula_name):\n    x = np.linspace(0, 1, 30)\n    y = np.linspace(0, 1, 30)\n    X, Y = np.meshgrid(x, y)\n    Z = copula_function(X, Y)\n\n\n    fig = plt.figure()\n    ax = plt.axes(projection='3d')\n    ax.contour3D(X, Y, Z, 50) #, cmap='binary')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title(copula_name)\n    #ax.set_zlabel('Copula')\n\ndef c_star(x, y):\n    return np.minimum([1], x) * np.minimum([1],y)\n\n\nplot_copula(c_star, \"C*\")\n\n\n\n\n\n\nCopula plus \\(C^{+}\\) This corresponds to maximal dependence between two variables. \\[\nC^{+} = \\min( \\min(1, x), \\min(1, y)) I_{(0, \\infty) \\times (0, \\infty)} (x, y)\n\\]\n\n\n\nCode\ndef c_plus(x, y):\n    return np.minimum(np.minimum([1], x), np.minimum([1],y))\n\n\nplot_copula(c_plus, \"C+\")\n\n\n\n\n\n\nCopula minus \\(C^{-}\\). This corresponds to maximal negative dependence between two variables. \\[\nC^{-} = max(0, min(1, x) + min (1, y) - 1) I_{(0, \\infty) \\times (0, \\infty)} (x, y)\n\\]\n\n\n\nCode\ndef c_minus(x, y):\n    return np.maximum(0, np.minimum([1], x) + np.minimum([1],y) - 1)\n\n\nplot_copula(c_minus, \"C-\")"
  },
  {
    "objectID": "posts/copula/index.html#properties",
    "href": "posts/copula/index.html#properties",
    "title": "Copula",
    "section": "Properties",
    "text": "Properties\nThe copulae plus and minus bound every other copula:\n\nTheorem 2 (Frechet) For any copula\n\\[\nC^{-} (x, y) \\leq C(x, y) \\leq C^{-} (x, y), \\forall x, y \\in \\mathbb{R}\n\\]\n\nAs every density, copulae have properties:\n\n\\(C: \\mathbb{R}^2 \\to [0,1]\\) is nondecreasing on every dimension\n\\(C(-\\infty, -\\infty) = 0\\) and \\(C(\\infty, \\infty) = 1\\), while iterating the limits in any order.\n\\(C\\) satisfies\n\n\\[\nC(\\min(\\mathbf{x},\\mathbf{y})) + C(\\max(\\mathbf{x},\\mathbf{y})) \\geq C(\\mathbf{x}) + C(\\mathbf{y}).\n\\]"
  },
  {
    "objectID": "posts/copula/index.html#sources",
    "href": "posts/copula/index.html#sources",
    "title": "Copula",
    "section": "Sources:",
    "text": "Sources:\n\nhttps://en.wikipedia.org/wiki/Copula_(probability_theory)#Sklar’s_theorem\nhttp://www.math.uni.wroc.pl/~szekli/documents/mumio/mumio-16-trans/skrypt-16.pdf\nhttps://jakevdp.github.io/PythonDataScienceHandbook/04.12-three-dimensional-plotting.html"
  },
  {
    "objectID": "posts/visualizing-cnn-layers/weights_cv.html",
    "href": "posts/visualizing-cnn-layers/weights_cv.html",
    "title": "Visualizing CNNs",
    "section": "",
    "text": "Even though the concept of convolutional neural networks is not new to me, I noticed a gap in my understanding. I couldn’t figure out how to approach visualization of convolutional neural network layers’ weights. It alweays seemed odd to me when I looked at examples found online.\nHere I will try to explore the concept to teach myself this interesting thing."
  },
  {
    "objectID": "posts/visualizing-cnn-layers/weights_cv.html#convolutional-neural-nets",
    "href": "posts/visualizing-cnn-layers/weights_cv.html#convolutional-neural-nets",
    "title": "Visualizing CNNs",
    "section": "Convolutional neural nets",
    "text": "Convolutional neural nets\nIn convolutional neural networks we operate on images. Each one is 2D grid of values representing every pixel. If the picture is in grayscale we only care for how dark or light each pixel is, so each image is represented as grid \\(n_{row} \\times n_{col}\\) with values representing darkness of each pixel.\nIf we use color pictures, we divide it into \\(3\\) channels - red, green, blue. For image with pixel size \\(n_{row} \\times n_{col}\\) we use one grid for red coulour, second for green and third for blue. This means each picture is represented with 3 grids one on top of the other. Dimensionality of this thing is \\((n_{row}, n_{col}, 3)\\).\n\n\n\nLayers of images. On the left grayscale image represented by only one matrix, on the right 3 channels of a colorful image.\n\n\n\nFilters\nFilters are introduced to smartly downscale an image while distilling the most important information convayed by the image. If we go back to grayscale setting, and assume we have \\((n_{row}, n_{col}, 1)\\) image, a single grid with pixel values, we introduce filter, for example \\(2 \\times 2\\) matrix that will be put on top of the image, place by place where it fits. Then we will calculate elementwise product of each overlaping entries, sum the values and we will end up with a smaller image.\n\n\n\nExample of grayscale image and \\(2\\times 2\\) filter\n\n\n\n\n\nApplying \\(2 \\times 2\\) filter to the example above.\n\n\nWhile constructing a concloutional layer in the model, we specify the size of a filter (\\(2 \\times 2\\), \\(3 \\times 3\\) etc.) and we decide on the number of filters we want to apply. In the example above we used only one filter but we could repeat the above process with the second one with different values than \\((1, 0),(2, 4)\\). In the example above we got output with dimensions \\((3, 3, 1, 1)\\). If we chose to apply second filter we would get second result, so overal thing would have dimensions \\((3, 3, 1, 2)\\). For specified number of filters \\(k\\) we would get \\((3, 3, 1, k)\\) dimensional tensor.\nValues of the filters are not specified by us before training - they are learned by the model. These are the things we may want ti visualize later to see how the model behaves.\nIf we take colorful image as input, with size \\((n_{row}, n_{col}, 3)\\), we construct filters that also have \\(3\\) channels - for example with size \\((2, 2, 3)\\). Each of the channels of the filter will be applied to the corresponding channel of a picture, the elementwise product will be calculated for each channel separately, as above. Then, before putting it all to the result matrix, the values will be summed together. We then would get flat \\((n_{row}', n_{col}', 1)\\) output. As before, we are not only applying one filter on the image - we can to this with many filters (\\(k\\)), so all of them will be stored as, for example \\((2, 2, 3, k)\\). And we will get output for each filter, so overal size will be \\((n_{row}', n_{col}', k)\\)"
  },
  {
    "objectID": "posts/visualizing-cnn-layers/weights_cv.html#get-convolutional-model",
    "href": "posts/visualizing-cnn-layers/weights_cv.html#get-convolutional-model",
    "title": "Visualizing CNNs",
    "section": "Get convolutional model",
    "text": "Get convolutional model\nWe get a trained model from keras package called VGG16. Out of this model we will look for convolutional layers.\n\n\nCode\nimport numpy as np\n\n\nfrom keras.applications.vgg16 import VGG16\nmodel = VGG16()\n\n#model.summary()\n\nfor idx, layer in enumerate(model.layers):\n    if 'conv' in layer.name:\n        filters, biases = layer.get_weights()\n        print(f\"Index: {idx})\", layer.name, filters.shape)\n    else:\n        print(f\"Index: {idx})\", layer.name)\n\n#weights from the second layer\n\nfilters, biases = model.layers[1].get_weights()\n\n#scaling\nf_min, f_max = filters.min(), filters.max()\nfilters = (filters - f_min) / (f_max - f_min)\n\n\nIndex: 0) input_3\nIndex: 1) block1_conv1 (3, 3, 3, 64)\nIndex: 2) block1_conv2 (3, 3, 64, 64)\nIndex: 3) block1_pool\nIndex: 4) block2_conv1 (3, 3, 64, 128)\nIndex: 5) block2_conv2 (3, 3, 128, 128)\nIndex: 6) block2_pool\nIndex: 7) block3_conv1 (3, 3, 128, 256)\nIndex: 8) block3_conv2 (3, 3, 256, 256)\nIndex: 9) block3_conv3 (3, 3, 256, 256)\nIndex: 10) block3_pool\nIndex: 11) block4_conv1 (3, 3, 256, 512)\nIndex: 12) block4_conv2 (3, 3, 512, 512)\nIndex: 13) block4_conv3 (3, 3, 512, 512)\nIndex: 14) block4_pool\nIndex: 15) block5_conv1 (3, 3, 512, 512)\nIndex: 16) block5_conv2 (3, 3, 512, 512)\nIndex: 17) block5_conv3 (3, 3, 512, 512)\nIndex: 18) block5_pool\nIndex: 19) flatten\nIndex: 20) fc1\nIndex: 21) fc2\nIndex: 22) predictions\n\n\nWith the explanation of the layers we can look at the layers in this model. First we get an input. Then we have first convolutional layer. From \\((3, 3, 3, 64)\\) we know that we have here \\(3 \\times 3\\) filters with \\(3\\) channels (input must be colorful) and the number of these filters is \\(64\\). After applying these filters on the image \\((n_{row}, n_{col}, 3)\\) we will get “image” with shape \\((n_{row}', n_{col}', 64)\\).\nIn the next layer we will have \\(3 \\times 3\\) filters that will need to deal wtth \\(64\\)-layer images. We choose to produce \\(64\\) such filters and so on.\nOther layers in this model that appear often are pooling layers. They just take image as it is and create smaller versions of it by taking for each small part of an image the maximum value (MaxPooling) or average value of the piece (AvgPooling). They don’t change depth or number of dimensions. Only 2D shape of an image \\((n_{row}', n_{col}') \\to (n_{row}'', n_{col}'')\\).\nAt the end of the model we are flattening everything to vectors and create fully connected neural nets to produce predictions at the end."
  },
  {
    "objectID": "posts/visualizing-cnn-layers/weights_cv.html#plot-some-filters",
    "href": "posts/visualizing-cnn-layers/weights_cv.html#plot-some-filters",
    "title": "Visualizing CNNs",
    "section": "Plot some filters",
    "text": "Plot some filters\nWe can take the first convolutional layer and take a look at the filters - we have there \\(64\\) filters, each has 3 channels and each of these channels is just \\(3 \\times 3\\) grid. We can create “heatmap” of this.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nnum_filters = 4\n\nfig, axs = plt.subplots(num_filters, filters.shape[2], sharey=True, figsize=(8, 12))\nfig.suptitle(\"Visualization of weights\")\nfor i in range(num_filters):\n    filter_0 = filters[:,:,:, i]\n    for j in range(filter_0.shape[2]):\n        axs[i,j].imshow(filter_0[:,:, j], cmap='gray')\n\n\n\n\n\nFigure 1: Every row is a visualized 3 x 3 filter with every column being a channel of that filter.\n\n\n\n\nSince in this layer every filter has three channels (each corresponding to a channel of a picture), we can in this case plot them as RGB figures.\n\n\nCode\nfig, axs = plt.subplots(5, 5, sharey=True, figsize = (8,8))\nfig.suptitle(\"Filters with all 3 channels\")\nfor i in range(5):\n    for j in range(5):\n        axs[i, j].imshow(filters[:,:,:, i*5 + j])\n\n\n\n\n\nFigure 2: Filters with all 3 channels displayed as RGB pictures.\n\n\n\n\nThis may look nice but I don’t think it is very informative. We can use the filters to transform a real picture and see the results."
  },
  {
    "objectID": "posts/visualizing-cnn-layers/weights_cv.html#plot-picture-after-applying-filters",
    "href": "posts/visualizing-cnn-layers/weights_cv.html#plot-picture-after-applying-filters",
    "title": "Visualizing CNNs",
    "section": "Plot picture after applying filters",
    "text": "Plot picture after applying filters\nWe can take a royalty free picture of a bird and put it through the first convolutional layer of the model.\n\n\n\nRoyalty free bird\n\n\n\n\nCode\nfrom keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.utils import load_img #keras.preprocessing.image is depricated\nfrom tensorflow.keras.utils import img_to_array\nfrom keras.models import Model\n\nmodel_one_layer = Model(inputs=model.inputs, outputs=model.layers[1].output)\nimg = load_img('bird.jpg', target_size=(224, 224))\n\n#image to array\nimg = img_to_array(img)\nimg = np.expand_dims(img, axis=0)\n#(num_samples, n_rows, n_cols, channels)\n\nimg = preprocess_input(img)\n\nfeature_maps = model_one_layer.predict(img)\n\n\n\n\nCode\nsquare = 5\n\nfig, axs = plt.subplots(square, square, sharey=True, figsize = (8,8))\nfig.suptitle(\"Image treated with filters\")\n\nfor i in range(square):\n    for j in range(square):\n        axs[i, j].imshow(feature_maps[0,:,:, i*square + j], cmap = 'gray')"
  },
  {
    "objectID": "posts/visualizing-cnn-layers/weights_cv.html#useful-links",
    "href": "posts/visualizing-cnn-layers/weights_cv.html#useful-links",
    "title": "Visualizing CNNs",
    "section": "Useful links",
    "text": "Useful links\n\nPicture of the bird: link\nMachine Learning Mastery blog post: link\nTowards Data Science blog post on convolutional layers: link\nPaper from 2013 on understanding convolutional layers: link\nPaper from 2015 on deep visualization: link\nDistilled paper from 2020 on visualizing weghts: link"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/zbieznosci/weights_cv.html",
    "href": "posts/zbieznosci/weights_cv.html",
    "title": "Zbieżności rozkładów",
    "section": "",
    "text": "W tym artykule postaram się przedstawić różne rodzaje zbieżności, jakie występują w rachunku prawdopodobieństwa. Ponieważ sama często mam z nimi problem, może taki post będzie pomocny też dla innych adeptów probabilistyki."
  },
  {
    "objectID": "posts/zbieznosci/weights_cv.html#rodzaje-zbieżności",
    "href": "posts/zbieznosci/weights_cv.html#rodzaje-zbieżności",
    "title": "Zbieżności rozkładów",
    "section": "Rodzaje zbieżności",
    "text": "Rodzaje zbieżności\nDefiniujemy różne rodzaje zbieżności. Mówimy, że ciąg zmiennych losowych \\((X_n)_{n=1}^\\infty\\) jest zbieżny do zmiennej losowej \\(X\\):\n\nPrawie na pewno\nprawie na pewno, jeśli\n\\[\nP({\\omega: \\lim_n X_n(\\omega) = X(\\omega)}) = 1\n\\]\nczyli kiedy miara zbioru na którym \\(\\lim_n X_n(\\omega) = X(\\omega)\\) wynosi 1, czyli różnią się na zbiorach miary zero. Odpowiada to zbieżności z teorii miary prawie wszędzie, gdzie zbieżność prawie wszędzie definiowana jest jako\nCiąg \\((f_n)\\) zbiega do funkcji \\(f\\) prawie wszędzie względem miary \\(\\mu\\), gdy istnieje zbiór mierzalny \\(E \\in \\mathcal{F}\\), taki że - \\(\\mu(E^c) = 0\\) - \\(\\lim_n f_n(x) = x\\) dla każdego \\(x \\in E\\).\n\n\nWedług prawdopodobieństwa\nwedług prawdopodobieństwa, jeśli dla każdego \\(\\epsilon > 0\\)\n\\[\nlim_n P(|X_n - X| > \\epsilon) = 0\n\\]\nczyli w granicy prawdopodobieństwo że się od siebie chociaż trochę różnią jest zerowe. Odpowiada to zbieżności według miary.\n\n\nWedług p-tego momentu (w \\(L^p\\))\ngdzie \\(0 < p < \\infty\\), jeśli \\(\\mathbb{E}|X|^p < \\infty\\) i \\(\\mathbb{E}|X_n|^p < \\infty\\) dla kolejnych \\(n =1, 2, 3, ...\\)\n\\[\n\\mathbb{E} |X_n - X|^p = 0\n\\] co odpowiada zbieżności w \\(L^p\\).\n\n\nZbieżność według rozkładu"
  },
  {
    "objectID": "posts/zbieznosci/weights_cv.html#zbieżność-prawie-na-pewno---twierdzenia",
    "href": "posts/zbieznosci/weights_cv.html#zbieżność-prawie-na-pewno---twierdzenia",
    "title": "Zbieżności rozkładów",
    "section": "Zbieżność prawie na pewno - twierdzenia",
    "text": "Zbieżność prawie na pewno - twierdzenia\n\nO X i Y\nJeżeli \\(X_n \\to^{pn} X\\) oraz \\(Y_n \\to^{pn} Y\\), to 1 Dla dowolnych \\(a, b \\in \\mathbb{R}\\) zachodzi \\(aX_n + bY_n \\to aX + bY\\)\nDowód: Weźmy dowolne \\(a, b \\in \\mathbb{R}\\). Wiemy, że \\(P({\\omega: \\lim_n X_n(\\omega) = X(\\omega)}) = 1\\) i \\(P({\\omega: \\lim_n Y_n(\\omega) = Y(\\omega)}) = 1\\)"
  }
]